{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "119f57db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import scipy.optimize\n",
    "import numpy\n",
    "import string\n",
    "import random\n",
    "from sklearn import linear_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d443b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGz(path):\n",
    "  for l in gzip.open(path, 'rt'):\n",
    "    yield eval(l)\n",
    "\n",
    "def readCSV(path):\n",
    "  f = gzip.open(path, 'rt')\n",
    "  f.readline()\n",
    "  for l in f:\n",
    "    yield l.strip().split(',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822bd6bb",
   "metadata": {},
   "source": [
    "*Part 2: Category Prediction*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef6c6726",
   "metadata": {},
   "outputs": [],
   "source": [
    "catDict = {\n",
    "  \"children\": 0,\n",
    "  \"comics_graphic\": 1,\n",
    "  \"fantasy_paranormal\": 2,\n",
    "  \"mystery_thriller_crime\": 3,\n",
    "  \"young_adult\": 4\n",
    "}\n",
    "\n",
    "genres = [\"children\", \"comics_graphic\",\"fantasy_paranormal\",\"mystery_thriller_crime\",\"young_adult\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69b171a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = list(readGz(\"train_Category.json.gz\"))\n",
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8066f90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split first\n",
    "train_data, test_data = train_test_split(train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "838f8ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute max length ONLY on training set\n",
    "max_len = max(len(d['review_text']) for d in train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c8cab2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: extract features\n",
    "train_texts = [d['review_text'] for d in train_data]\n",
    "train_ratings = np.array([d['rating'] for d in train_data]).reshape(-1, 1)\n",
    "train_votes = np.array([d['n_votes'] for d in train_data]).reshape(-1, 1)\n",
    "train_length = np.array([len(d['review_text']) / max_len for d in train_data]).reshape(-1, 1)\n",
    "train_rating_votes  = train_ratings * train_votes\n",
    "train_votes_length  = train_votes * train_length\n",
    "train_length_rating = train_length * train_ratings\n",
    "train_genres = [d['genre'] for d in train_data]\n",
    "\n",
    "test_texts = [d['review_text'] for d in test_data]\n",
    "test_ratings = np.array([d['rating'] for d in test_data]).reshape(-1, 1)\n",
    "test_votes = np.array([d['n_votes'] for d in test_data]).reshape(-1, 1)\n",
    "test_length = np.array([len(d['review_text']) / max_len for d in test_data]).reshape(-1, 1)\n",
    "test_rating_votes  = test_ratings * test_votes\n",
    "test_votes_length  = test_votes * test_length\n",
    "test_length_rating = test_length * test_ratings\n",
    "test_genres = [d['genre'] for d in test_data]\n",
    "\n",
    "# Step 2: build text features (TF-IDF) for train\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=100000,      # allow large vocab\n",
    "    min_df=1,                # filter rare words\n",
    "    max_df=0.5,              # filter super-common words\n",
    "    ngram_range= (1,1),\n",
    "    stop_words='english'\n",
    ")\n",
    "\n",
    "train_X_text = tfidf.fit_transform(train_texts)\n",
    "test_X_text = tfidf.transform(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f84c7980",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sel = train_X_text\n",
    "X_test_sel = test_X_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a76a450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine numeric feats for train\n",
    "train_num = np.hstack([\n",
    "    train_ratings,\n",
    "    train_votes,\n",
    "    train_length,\n",
    "    train_rating_votes,\n",
    "    train_votes_length,\n",
    "    train_length_rating\n",
    "])\n",
    "\n",
    "# Combine numeric feats for test\n",
    "test_num = np.hstack([\n",
    "    test_ratings,\n",
    "    test_votes,\n",
    "    test_length,\n",
    "    test_rating_votes,\n",
    "    test_votes_length,\n",
    "    test_length_rating\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42547cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "train_num_scaled = scaler.fit_transform(train_num)\n",
    "test_num_scaled  = scaler.transform(test_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13db23a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num_sparse = csr_matrix(train_num_scaled)\n",
    "test_num_sparse  = csr_matrix(test_num_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c3a39b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = hstack([X_train_sel, train_num_sparse])\n",
    "X_test  = hstack([X_test_sel,  test_num_sparse])\n",
    "y_train = train_genres\n",
    "y_test = test_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "932f507b",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "y_test_enc  = le.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fbb5225b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\study\\Coding\\Anaconda\\envs\\tfenv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clf = linear_model.LogisticRegression(\n",
    "        C=2,\n",
    "        multi_class='multinomial',\n",
    "        solver='lbfgs',\n",
    "        max_iter=1000\n",
    "    )\n",
    "clf.fit(X_train, y_train_enc)\n",
    "test_preds = clf.predict_proba(X_test)\n",
    "test_pred_labels = le.inverse_transform(np.argmax(test_preds, axis=1))\n",
    "test_acc  = accuracy_score(y_test, test_pred_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b2373b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7714\n"
     ]
    }
   ],
   "source": [
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fca1f212",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\study\\Coding\\Anaconda\\envs\\tfenv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.77245\n"
     ]
    }
   ],
   "source": [
    "clf2 = linear_model.LogisticRegression(\n",
    "        C=2.5,\n",
    "        multi_class='multinomial',\n",
    "        solver='lbfgs',\n",
    "        max_iter=1000\n",
    "    )\n",
    "clf2.fit(X_train, y_train_enc)\n",
    "test_preds2 = clf2.predict_proba(X_test)\n",
    "test_pred_labels2 = le.inverse_transform(np.argmax(test_preds2, axis=1))\n",
    "test_acc2  = accuracy_score(y_test, test_pred_labels2)\n",
    "print(test_acc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8ce61b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\study\\Coding\\Anaconda\\envs\\tfenv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.77265\n"
     ]
    }
   ],
   "source": [
    "clf3 = linear_model.LogisticRegression(\n",
    "        C=2.8,\n",
    "        multi_class='multinomial',\n",
    "        solver='lbfgs',\n",
    "        max_iter=1000\n",
    "    )\n",
    "clf3.fit(X_train, y_train_enc)\n",
    "test_preds3 = clf3.predict_proba(X_test)\n",
    "test_pred_labels3 = le.inverse_transform(np.argmax(test_preds3, axis=1))\n",
    "test_acc3  = accuracy_score(y_test, test_pred_labels3)\n",
    "print(test_acc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4738a044",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\study\\Coding\\Anaconda\\envs\\tfenv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.77305\n"
     ]
    }
   ],
   "source": [
    "clf4 = linear_model.LogisticRegression(\n",
    "        C=3,\n",
    "        multi_class='multinomial',\n",
    "        solver='lbfgs',\n",
    "        max_iter=1000\n",
    "    )\n",
    "clf4.fit(X_train, y_train_enc)\n",
    "test_preds4 = clf4.predict_proba(X_test)\n",
    "test_pred_labels4 = le.inverse_transform(np.argmax(test_preds4, axis=1))\n",
    "test_acc4  = accuracy_score(y_test, test_pred_labels4)\n",
    "print(test_acc4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2126f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\study\\Coding\\Anaconda\\envs\\tfenv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7733\n"
     ]
    }
   ],
   "source": [
    "clf5 = linear_model.LogisticRegression(\n",
    "        C=3.3,\n",
    "        multi_class='multinomial',\n",
    "        solver='lbfgs',\n",
    "        max_iter=1000\n",
    "    )\n",
    "clf5.fit(X_train, y_train_enc)\n",
    "test_preds5 = clf5.predict_proba(X_test)\n",
    "test_pred_labels5 = le.inverse_transform(np.argmax(test_preds5, axis=1))\n",
    "test_acc5  = accuracy_score(y_test, test_pred_labels5)\n",
    "print(test_acc5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33174926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# 1. Read PREDICTION dataset\n",
    "# ---------------------------------------------------\n",
    "prediction_data = list(readGz(\"test_Category.json.gz\"))\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 2. Extract features (using TRAIN parameters like max_len)\n",
    "# ---------------------------------------------------\n",
    "pred_texts = [d['review_text'] for d in prediction_data]\n",
    "pred_ratings = np.array([d['rating'] for d in prediction_data]).reshape(-1, 1)\n",
    "pred_votes = np.array([d['n_votes'] for d in prediction_data]).reshape(-1, 1)\n",
    "\n",
    "# normalize using TRAIN max_len\n",
    "pred_length = np.array([len(d['review_text']) / max_len for d in prediction_data]).reshape(-1, 1)\n",
    "\n",
    "# interaction features\n",
    "pred_rating_votes  = pred_ratings * pred_votes\n",
    "pred_votes_length  = pred_votes * pred_length\n",
    "pred_length_rating = pred_length * pred_ratings\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 3. TF-IDF transform (DO NOT FIT!)\n",
    "# ---------------------------------------------------\n",
    "pred_X_text = tfidf.transform(pred_texts)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 4. Feature selection (DO NOT FIT!)\n",
    "# ---------------------------------------------------\n",
    "X_pred_sel = pred_X_text\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 5. Numeric feature scaling (DO NOT FIT!)\n",
    "# ---------------------------------------------------\n",
    "pred_num = np.hstack([\n",
    "    pred_ratings,\n",
    "    pred_votes,\n",
    "    pred_length,\n",
    "    pred_rating_votes,\n",
    "    pred_votes_length,\n",
    "    pred_length_rating\n",
    "])\n",
    "\n",
    "pred_num_scaled = scaler.transform(pred_num)\n",
    "pred_num_sparse = csr_matrix(pred_num_scaled)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 6. Final prediction feature matrix\n",
    "# ---------------------------------------------------\n",
    "X_pred_final = hstack([X_pred_sel, pred_num_sparse])\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 7. Predict\n",
    "# ---------------------------------------------------\n",
    "pred_preds = clf5.predict_proba(X_pred_final)\n",
    "\n",
    "# final predicted class index\n",
    "pred_labels_enc = np.argmax(pred_preds, axis=1)\n",
    "\n",
    "# convert index â†’ genre string\n",
    "pred_labels = le.inverse_transform(pred_labels_enc)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 8. Write output file\n",
    "# ---------------------------------------------------\n",
    "with open(\"predictions_Category.csv\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"userID,reviewID,prediction\\n\")\n",
    "    for d, genre in zip(prediction_data, pred_labels):\n",
    "        cat_id = catDict[genre]\n",
    "        f.write(f\"{d['user_id']},{d['review_id']},{cat_id}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
