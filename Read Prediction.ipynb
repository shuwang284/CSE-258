{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "119f57db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import scipy.optimize\n",
    "import numpy\n",
    "import string\n",
    "import random\n",
    "from sklearn import linear_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d443b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGz(path):\n",
    "  for l in gzip.open(path, 'rt'):\n",
    "    yield eval(l)\n",
    "\n",
    "def readCSV(path):\n",
    "  f = gzip.open(path, 'rt')\n",
    "  f.readline()\n",
    "  for l in f:\n",
    "    yield l.strip().split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8daee63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "allRatings = []\n",
    "for l in readCSV(\"train_Interactions.csv.gz\"):\n",
    "    allRatings.append(l)\n",
    "\n",
    "ratingsTrain = allRatings[:190000]\n",
    "ratingsValid = allRatings[190000:]\n",
    "ratingsPerUser = defaultdict(list)\n",
    "ratingsPerItem = defaultdict(list)\n",
    "for u,b,r in ratingsTrain:\n",
    "    ratingsPerUser[u].append((b,r))\n",
    "    ratingsPerItem[b].append((u,r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ea66748",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Would-read baseline: just rank which books are popular and which are not, and return '1' if a book is among the top-ranked\n",
    "\n",
    "bookCount = defaultdict(int)\n",
    "totalRead = 0\n",
    "\n",
    "for user,book,_ in readCSV(\"train_Interactions.csv.gz\"):\n",
    "  bookCount[book] += 1\n",
    "  totalRead += 1\n",
    "\n",
    "mostPopular = [(bookCount[x], x) for x in bookCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7485a481",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateValidation(allRatings, ratingsValid):\n",
    "    # Using ratingsValid, generate two sets:\n",
    "    # readValid: set of (u,b) pairs in the validation set\n",
    "    # notRead: set of (u,b') pairs, containing one negative (not read) for each row (u) in readValid  \n",
    "    # Both should have the same size as ratingsValid\n",
    "\n",
    "    allRead = set((d[0], d[1]) for d in allRatings)\n",
    "    readValid = set((d[0], d[1]) for d in ratingsValid)\n",
    "    bookperuser = defaultdict(set)\n",
    "    for u, b in allRead:\n",
    "        bookperuser[u].add(b)\n",
    "    \n",
    "    notRead = set()\n",
    "    allBooks = list({b for _, b in allRead})  # all unique book IDs\n",
    "\n",
    "    for u, b in readValid:\n",
    "        unread = random.choice(allBooks)\n",
    "        while unread in bookperuser[u]:\n",
    "            unread = random.choice(allBooks)\n",
    "        notRead.add((u, unread))\n",
    "\n",
    "    return readValid, notRead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "672243f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sim_binary(b1, b2, ratingsPerItem):\n",
    "    users1 = set(u for u,_ in ratingsPerItem.get(b1, []))\n",
    "    users2 = set(u for u,_ in ratingsPerItem.get(b2, []))\n",
    "    if not users1 or not users2: return 0.0\n",
    "    inter = len(users1 & users2)\n",
    "    denom = math.sqrt(len(users1) * len(users2))\n",
    "    return inter / denom if denom else 0.0\n",
    "\n",
    "def cosine_weighted(b1, b2, ratingsPerItem):\n",
    "    users1 = set(u for u,_ in ratingsPerItem.get(b1, []))\n",
    "    users2 = set(u for u,_ in ratingsPerItem.get(b2, []))\n",
    "    if not users1 or not users2: return 0.0\n",
    "    inter = len(users1 & users2)\n",
    "    denom = (len(users1)**0.25)*(len(users2)**0.25)\n",
    "    return inter / denom if denom else 0.0\n",
    "\n",
    "def jaccard_sim_binary_items(b1, b2, ratingsPerItem):\n",
    "    users1 = set(u for u,_ in ratingsPerItem.get(b1, []))\n",
    "    users2 = set(u for u,_ in ratingsPerItem.get(b2, []))\n",
    "    if not users1 or not users2: return 0.0\n",
    "    inter = len(users1 & users2)\n",
    "    union = len(users1 | users2)\n",
    "    return inter / union if union else 0.0\n",
    "\n",
    "def jaccard_sim_binary_users(u1, u2, ratingsPerUser):\n",
    "    books1 = set(b for b,_ in ratingsPerUser.get(u1, []))\n",
    "    books2 = set(b for b,_ in ratingsPerUser.get(u2, []))\n",
    "    if not books1 or not books2: return 0.0\n",
    "    inter = len(books1 & books2)\n",
    "    union = len(books1 | books2)\n",
    "    return inter / union if union else 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32e218bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_feature_df(allRatings, ratingsValid, ratingsPerUser, ratingsPerItem, bookCount, totalRead):\n",
    "    readValid, notRead = generateValidation(allRatings, ratingsValid)\n",
    "    data = []\n",
    "    for (u,b,label) in [(u,b,1) for (u,b) in readValid] + [(u,b,0) for (u,b) in notRead]:\n",
    "\n",
    "        # user’s read books\n",
    "        user_books = [bk for bk,_ in ratingsPerUser.get(u, [])]\n",
    "        # item’s readers\n",
    "        book_users = [us for us,_ in ratingsPerItem.get(b, [])]\n",
    "\n",
    "        if not user_books or not book_users:\n",
    "            data.append([u,b,0,0,0,0,bookCount.get(b,0)/totalRead,label])\n",
    "            continue\n",
    "\n",
    "        # max similarities\n",
    "        sim_cosine = max(cosine_sim_binary(b, other, ratingsPerItem) for other in user_books)\n",
    "        sim_weighted = max(cosine_weighted(b, other, ratingsPerItem) for other in user_books)\n",
    "        sim_jaccard_item = max(jaccard_sim_binary_items(b, other, ratingsPerItem) for other in user_books)\n",
    "        sim_jaccard_user = max(jaccard_sim_binary_users(u, other, ratingsPerUser) for other in book_users)\n",
    "        popScore = bookCount.get(b,0) / totalRead\n",
    "\n",
    "        data.append([u,b,sim_cosine,sim_weighted,sim_jaccard_item,sim_jaccard_user,popScore,label])\n",
    "\n",
    "    df = pd.DataFrame(data, columns=[\n",
    "        \"user\",\"book\",\"cosine\",\"cosine_weighted\",\"item_jaccard\",\"user_jaccard\",\"pop\",\"label\"\n",
    "    ])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ab8f281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_logistic_model(df):\n",
    "    X = df[[\"cosine\",\"cosine_weighted\",\"item_jaccard\",\"user_jaccard\",\"pop\"]]\n",
    "    y = df[\"label\"]\n",
    "    model = linear_model.LogisticRegression(max_iter=500)\n",
    "    model.fit(X, y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72cdd519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_balanced_per_user(df, model):\n",
    "    X = df[[\"cosine\",\"cosine_weighted\",\"item_jaccard\",\"user_jaccard\",\"pop\"]]\n",
    "    df[\"prob\"] = model.predict_proba(X)[:,1]\n",
    "\n",
    "    preds = []\n",
    "    for u, grp in df.groupby(\"user\"):\n",
    "        # sort by predicted probability descending\n",
    "        sorted_grp = grp.sort_values(\"prob\", ascending=False)\n",
    "        n = len(sorted_grp)\n",
    "        cutoff = n//2\n",
    "        sorted_grp[\"pred\"] = 0\n",
    "        sorted_grp.iloc[:cutoff, sorted_grp.columns.get_loc(\"pred\")] = 1\n",
    "        preds.append(sorted_grp)\n",
    "    df_pred = pd.concat(preds, ignore_index=True)\n",
    "    return df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7aa2146",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(df_pred):\n",
    "    return accuracy_score(df_pred[\"label\"], df_pred[\"pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c16762b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature table built: (19999, 8)\n",
      "Balanced-per-user logistic model accuracy: 0.7799\n"
     ]
    }
   ],
   "source": [
    "df = build_feature_df(allRatings, ratingsValid, ratingsPerUser, ratingsPerItem, bookCount, totalRead)\n",
    "print(\"Feature table built:\", df.shape)\n",
    "\n",
    "model = train_logistic_model(df)\n",
    "df_pred = predict_balanced_per_user(df, model)\n",
    "acc = evaluate_accuracy(df_pred)\n",
    "print(f\"Balanced-per-user logistic model accuracy: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44b5b887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_feature_df_for_pairs(pairs_path, ratingsPerUser, ratingsPerItem, bookCount, totalRead):\n",
    "    \"\"\"Reuses the same feature computation logic as training but for unlabeled test pairs.\"\"\"\n",
    "    test_data = []\n",
    "    with open(pairs_path) as f:\n",
    "        next(f)  # skip header line\n",
    "        for line in f:\n",
    "            u,b = line.strip().split(',')\n",
    "            user_books = [bk for bk,_ in ratingsPerUser.get(u, [])]\n",
    "            book_users = [us for us,_ in ratingsPerItem.get(b, [])]\n",
    "\n",
    "            if not user_books or not book_users:\n",
    "                test_data.append([u,b,0,0,0,0,bookCount.get(b,0)/totalRead])\n",
    "                continue\n",
    "\n",
    "            sim_cosine = max(cosine_sim_binary(b, other, ratingsPerItem) for other in user_books)\n",
    "            sim_weighted = max(cosine_weighted(b, other, ratingsPerItem) for other in user_books)\n",
    "            sim_jaccard_item = max(jaccard_sim_binary_items(b, other, ratingsPerItem) for other in user_books)\n",
    "            sim_jaccard_user = max(jaccard_sim_binary_users(u, other, ratingsPerUser) for other in book_users)\n",
    "            popScore = bookCount.get(b,0) / totalRead\n",
    "\n",
    "            test_data.append([u,b,sim_cosine,sim_weighted,sim_jaccard_item,sim_jaccard_user,popScore])\n",
    "\n",
    "    df_test = pd.DataFrame(test_data, columns=[\n",
    "        \"user\",\"book\",\"cosine\",\"cosine_weighted\",\"item_jaccard\",\"user_jaccard\",\"pop\"\n",
    "    ])\n",
    "    return df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6af5eb04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done. Predictions written to predictions_Read.csv\n"
     ]
    }
   ],
   "source": [
    "df_test = build_feature_df_for_pairs(\"pairs_Read.csv\", ratingsPerUser, ratingsPerItem, bookCount, totalRead)\n",
    "df_pred = predict_balanced_per_user(df_test, model)\n",
    "\n",
    "predictions = open(\"predictions_Read.csv\", 'w')\n",
    "predictions.write(\"userID,bookID,Prediction\\n\")\n",
    "\n",
    "for _, row in df_pred.iterrows():\n",
    "    predictions.write(f\"{row.user},{row.book},{row.pred}\\n\")\n",
    "\n",
    "predictions.close()\n",
    "print(\"✅ Done. Predictions written to predictions_Read.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
